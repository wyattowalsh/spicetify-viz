# Building a Spicetify Visualizer: Key Findings (June 2025)

This document outlines the key findings from the Spicetify documentation and provides a strategic guide for developing a Spotify visualizer as a Spicetify Custom App.

## Executive Summary

Building a visualizer is not only feasible but is a perfect use case for a Spicetify **Custom App**. The Spicetify API provides the necessary tools to access track information and, most importantly, audio analysis data.

The most critical API for this project is `Spicetify.getAudioData()`. However, it's essential to understand a key architectural constraint from the outset:

**Limitation: Static vs. Real-Time Audio Data**
The `getAudioData()` function provides a **static audio analysis** of a track, generated by Spotify's servers. This is not a real-time stream of audio frequency data (like FFT data) that traditional visualizers often use. The data includes pre-computed beats, bars, segments, loudness levels, and pitches for the entire track.

This means your visualizer will be **choreographed** to the song's structure rather than reacting to the raw, real-time audio output. This is a design constraint, but it also opens up opportunities for highly synchronized and musically-aware visuals.

## Revision 2: Incorporating `spicetify-creator` and Real-Time Analysis

This revision extends the original guide with a more modern development workflow using `spicetify-creator` and introduces a superior architectural approach for real-time audio visualization by leveraging the Web Audio API.

## 1. Project Setup: The Modern `spicetify-creator` Workflow

While the manual setup process works, the official `spicetify-creator` toolchain provides a much more robust and efficient development experience with features like project scaffolding, automatic builds, and hot-reloading.

**To get started with `spicetify-creator`:**

1.  **Initialize Your Project:** Open your terminal and run the scaffolding command:
    ```bash
    npx @spicetify/creator init visualizer-app --type=app
    ```
    This creates a new React-based project template for a Custom App.

2.  **Start the Dev Server:** Navigate into your new project directory and start the development server:
    ```bash
    cd visualizer-app
    npm install
    npm start
    ```

3.  **Enable and Watch:** The development server will guide you, but the key step is to tell Spicetify to watch your app for changes:
    ```bash
    spicetify-creator-dev --watch
    ```
    Now, any changes you make to your React components will be automatically compiled and reloaded within Spotify. This eliminates the need for manual `spicetify apply` commands during development.

## 2. Core Logic: Two Powerful Architectural Approaches

The key to your visualizer is how you analyze the audio. There are two primary methods, each with distinct advantages.

### Approach A: Choreographed Visuals (Static Analysis)

-   **API:** `Spicetify.getAudioData()`
-   **How it Works:** Fetches a detailed, pre-computed analysis of the entire track from Spotify's servers. This includes beats, bars, segments, loudness, and pitch information.
-   **Pros:** Perfect for creating visuals that are perfectly synchronized with a song's known structure. Allows for complex, "choreographed" animations that can anticipate changes in the music. Simpler to implement.
-   **Cons:** Not real-time. The visualizer is playing back a pre-determined script, not reacting to the live audio stream.

### Approach B: Real-Time Reactive Visuals (Web Audio API)

-   **API:** Standard Web Audio API (`AudioContext`, `AnalyserNode`)
-   **How it Works:** This is the professional standard for web-based visualizers. You directly tap into Spotify's underlying HTML `<audio>` element, create an `AudioContext`, and use an `AnalyserNode` to get real-time frequency and waveform data (FFT analysis) on every animation frame.
-   **Pros:** Truly reactive visuals that respond to the nuances of the audio as it plays. Enables classic visualizer effects like spectrum bars, oscilloscopes, and particle systems driven by frequency bins (bass, mids, treble).
-   **Cons:** Can be more complex to set up. Requires careful handling of the `AudioContext` lifecycle.

**Recommendation:** For a state-of-the-art visualizer, **Approach B is strongly recommended**. It provides the creative freedom and dynamic results users expect. The following sections will focus on this superior approach.

## 3. Building the Visualizer UI (Enhanced)

Drawing inspiration from advanced web projects like the [3D Audio Visualizer on Codrops](https://tympanus.net/codrops/2025/06/18/coding-a-3d-audio-visualizer-with-three-js-gsap-web-audio-api/), we can plan for a more sophisticated UI.

-   **Rendering with Three.js:** For stunning 2D or 3D visuals, **Three.js** is the ideal library. You can create a scene within your app's React component and render it to a `<canvas>`. This allows for complex geometries, custom shaders that react to audio data, and advanced post-processing effects.
-   **Immersive Atmosphere:** Use a combination of a large, central visual element (like the "anomaly orb" from the Codrops article) and a field of background particles to create a sense of depth and immersion.
-   **Polished Animations with GSAP:** While Three.js handles the core rendering, use a library like **GSAP (GreenSock Animation Platform)** for all UI-related animations. This includes smooth transitions for settings panels, interactive elements, and camera movements. GSAP's `Draggable` and `InertiaPlugin` can be used to create slick, physics-based UI panels that users can toss around the screen.

## 4. Example Code Skeleton (Real-Time Web Audio API)

This skeleton demonstrates how to hook into Spotify's audio element and use the Web Audio API from within a `spicetify-creator` React component.

```jsx
// src/app.tsx

import React, { useEffect, useRef, useState } from 'react';

const App = () => {
    const canvasRef = useRef(null);
    const [analyser, setAnalyser] = useState(null);

    useEffect(() => {
        // Find the active Spotify audio element
        const audio = document.querySelector("audio");
        if (!audio) {
            console.error("Spicetify-viz: Could not find audio element.");
            return;
        }

        const audioContext = new (window.AudioContext || window.webkitAudioContext)();
        const source = audioContext.createMediaElementSource(audio);
        const an = audioContext.createAnalyser();

        an.fftSize = 2048; // Fast Fourier Transform size
        const bufferLength = an.frequencyBinCount;
        const dataArray = new Uint8Array(bufferLength);

        source.connect(an);
        an.connect(audioContext.destination);

        setAnalyser(an);

        // Animation Loop
        const renderFrame = () => {
            requestAnimationFrame(renderFrame);
            an.getByteFrequencyData(dataArray);

            const canvas = canvasRef.current;
            const ctx = canvas.getContext('2d');
            
            // --- YOUR DRAWING LOGIC HERE ---
            ctx.fillStyle = 'rgb(0, 0, 0)';
            ctx.fillRect(0, 0, canvas.width, canvas.height);

            const barWidth = (canvas.width / bufferLength) * 2.5;
            let barHeight;
            let x = 0;

            for(let i = 0; i < bufferLength; i++) {
                barHeight = dataArray[i];
                
                // Example: Draw spectrum bars
                const r = barHeight + (25 * (i/bufferLength));
                const g = 250 * (i/bufferLength);
                const b = 50;
                
                ctx.fillStyle = "rgb(" + r + "," + g + "," + b + ")";
                ctx.fillRect(x, canvas.height - barHeight, barWidth, barHeight);

                x += barWidth + 1;
            }
             // --- END DRAWING LOGIC ---
        };
        
        renderFrame();

    }, []);

    return <canvas ref={canvasRef} id="visualizer-canvas" width={window.innerWidth} height={window.innerHeight} />;
};

export default App;
```

## 5. Next Steps & Further Research (Updated)

1.  **Master the Web Audio API:** This is now the most critical API for your project. Understand `AnalyserNode`, `fftSize`, and how to interpret frequency data.
2.  **Learn Three.js and GLSL Shaders:** To create truly unique and performant visuals, you will want to move beyond the Canvas 2D API. Three.js is the standard, and writing your own GLSL shaders will allow you to pass audio data directly to the GPU for incredible effects. The Codrops article is an excellent starting point for this.
3.  **Explore `spicetify-creator`:** Read the documentation for `spicetify-creator` [[https://github.com/spicetify/spicetify-creator](https://github.com/spicetify/spicetify-creator)] to understand its full capabilities, including how to build for production and package your app.
4.  **UI/UX:** Consider the Spotify UI context. A recent change moved icons to the top bar [[https://discuss.cachyos.org/t/anyone-using-spicetify-with-spotify/10029](https://discuss.cachyos.org/t/anyone-using-spicetify-with-spotify/10029)]. When designing settings or controls, ensure they feel integrated with the modern Spotify client.

## 6. Architecting for Extensibility

A key goal for `spicetify-viz` is to create a vibrant ecosystem where the community can easily contribute new visualization styles. To facilitate this, the project is built on a highly extensible architecture.

### Core Principles

1.  **Engine vs. Style Separation:** The core logic (audio processing, render loop, Spicetify integration) is completely decoupled from the rendering logic of individual visual styles.
2.  **Visualizer Class Contract:** A `BaseVisualizer` class establishes a clear contract. Every new visualizer must extend this class, ensuring it can be seamlessly integrated into the main engine.
3.  **Centralized Registry:** A single registry file (`src/visualizers/index.ts`) serves as the source of truth for all available visualizers, making them easy to discover and manage.

This architecture ensures that contributors don't need to understand the complexities of the core engine. They can focus entirely on the creative task of writing rendering logic by implementing a simple class.

### How to Contribute a New Visualization

We've created a comprehensive guide for developers who want to add new visual styles to the project. This document provides a step-by-step walkthrough of the entire process, from creating your class file to implementing the `draw` method and registering your visualizer.

**[Read the "Creating Visualizations" Guide &rarr;](./docs/contributing/creating-visualizations)**
